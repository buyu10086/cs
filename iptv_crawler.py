import requests
import time
import random
import json
from datetime import datetime, timedelta
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import logging
import multiprocessing
from typing import Tuple, List, Dict, Optional

# -------------------------- å…¨å±€é…ç½®ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šåˆ é™¤å¤±æ•ˆå¤®è§†æº + å¼ºåŒ–kakaxi-1/zuboæºæå–ï¼‰ --------------------------
# 1. æ•°æ®æºé…ç½®ï¼ˆä¿ç•™æœ‰æ•ˆæºï¼Œé‡ç‚¹ä¿éšœkakaxi-1/zuboæºæŠ“å–æå–ï¼‰
IPTV_SOURCE_URLS = [
    # é‡ç‚¹ä¿éšœï¼škakaxi-1/zubo æºï¼ˆç¡®ä¿è¯¥æºé¢‘é“100%æå–ï¼‰
    "https://raw.githubusercontent.com/kakaxi-1/zubo/refs/heads/main/IPTV.txt",
    "https://raw.githubusercontent.com/kakaxi-1/IPTV/refs/heads/main/ipv4.txt",
    "https://raw.githubusercontent.com/8080713/iptv-api666/refs/heads/main/output/result.m3u",
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
    "https://gh-proxy.com/raw.githubusercontent.com/vbskycn/iptv/refs/heads/master/tv/iptv4.m3u",
    # ä¿ç•™æ–°å¢çš„zwc456babyæº
    "https://raw.githubusercontent.com/zwc456baby/iptv_alive/refs/heads/master/live.m3u"
]

# æ ¸å¿ƒï¼šåˆ é™¤æ‰€æœ‰å¤±æ•ˆå¤®è§†æºï¼Œä»…ä¿ç•™å½“å‰100%å¯ç”¨çš„å®˜æ–¹/åˆè§„æºï¼ˆé¿å…405æ‹¦æˆªï¼Œç¡®ä¿éªŒè¯æˆåŠŸï¼‰
OFFICIAL_SOURCES = {
    # ä»…ä¿ç•™å¯ç”¨çš„å¤®è§†/å«è§†/å’ªå’•æºï¼ˆç»è¿‡éªŒè¯ï¼Œæ— æ‹¦æˆªé£é™©ï¼‰
    "CCTV1 ç»¼åˆï¼ˆå¯ç”¨ï¼‰": "http://117.148.123.202:8080/PLTV/88888888/224/3221225618/index.m3u8",
    "CCTV5 ä½“è‚²ï¼ˆå¯ç”¨ï¼‰": "http://117.148.123.202:8080/PLTV/88888888/224/3221225622/index.m3u8",
    "CCTV13 æ–°é—»ï¼ˆå¯ç”¨ï¼‰": "http://117.148.123.202:8080/PLTV/88888888/224/3221225630/index.m3u8",
    # è¿è¥å•†å¯ç”¨å«è§†æº
    "æ¹–å—å«è§†ï¼ˆå¯ç”¨ï¼‰": "http://117.148.123.202:8080/PLTV/88888888/224/3221225726/index.m3u8",
    "æµ™æ±Ÿå«è§†ï¼ˆå¯ç”¨ï¼‰": "http://117.148.123.202:8080/PLTV/88888888/224/3221225730/index.m3u8",
    # å’ªå’•å¯ç”¨æº
    "å’ªå’•ä½“è‚²é«˜æ¸…ï¼ˆå¯ç”¨ï¼‰": "https://hls.miguvideo.com/hls/main/0/0/1.m3u8"
}

# 2. æ•ˆç‡æ ¸å¿ƒé…ç½®ï¼ˆé’ˆå¯¹æ€§ä¼˜åŒ–kakaxi-1/zuboæºï¼šå»¶é•¿æŠ“å–è¶…æ—¶ï¼Œæé«˜æå–æˆåŠŸç‡ï¼‰
TIMEOUT_VERIFY = 5.0  # å»¶é•¿éªŒè¯è¶…æ—¶ï¼Œé€‚é…è¿è¥å•†æº
TIMEOUT_FETCH = 15    # é‡ç‚¹å»¶é•¿æŠ“å–è¶…æ—¶ï¼ˆé€‚é…kakaxi-1/zuboæµ·å¤–æºï¼Œé¿å…æŠ“å–ä¸­æ–­ï¼‰
MIN_VALID_CHANNELS = 1
MAX_THREADS_VERIFY_BASE = 100
MAX_THREADS_FETCH_BASE = 15  # å¢åŠ æŠ“å–çº¿ç¨‹ï¼Œä¿éšœkakaxi-1/zuboæºä¼˜å…ˆæŠ“å–
MIN_DELAY = 0.05
MAX_DELAY = 0.15
DISABLE_SSL_VERIFY = True
BATCH_PROCESS_SIZE = 200  # å¢å¤§æ‰¹å¤„ç†å®¹é‡ï¼Œé€‚é…kakaxi-1/zuboæºå¤§é‡é¢‘é“

# 3. è¾“å‡ºä¸ç¼“å­˜é…ç½®ï¼ˆå¢å¤§ç¼“å­˜ï¼Œä¿éšœkakaxi-1/zuboæºé¢‘é“ç¼“å­˜ï¼‰
OUTPUT_FILE = "iptv_playlist.m3u8"
CACHE_FILE = "iptv_persist_cache.json"
TEMP_CACHE_SET = set()
CACHE_EXPIRE_HOURS = 24
REMOVE_DUPLICATE_CHANNELS = False  # ä¸´æ—¶å…³é—­å»é‡ï¼Œç¡®ä¿kakaxi-1/zuboæºé¢‘é“ä¸ä¸¢å¤±ï¼ˆåç»­æŒ‰URLå»é‡ï¼‰
REMOVE_LOCAL_URLS = True
ENABLE_EMOJI = False
CACHE_MAX_SIZE = 10000  # å¤§å¹…å¢å¤§ç¼“å­˜å®¹é‡ï¼Œå®¹çº³kakaxi-1/zuboæºå¤§é‡é¢‘é“

# 4. æ’åº+æ’­æ”¾ç«¯é…ç½®ï¼ˆä¿éšœkakaxi-1/zuboæºé¢‘é“å½’ç±»æ­£å¸¸ï¼‰
CHANNEL_SORT_ENABLE = True
CCTV_SORT_ENABLE = True
WEISHI_SORT_ENABLE = True
LOCAL_SORT_ENABLE = True
FEATURE_SORT_ENABLE = True
DIGITAL_SORT_ENABLE = True
MANUAL_SOURCE_NUM = 4  # ä¿ç•™4ä¸ªå¤‡ç”¨æºï¼Œå……åˆ†åˆ©ç”¨kakaxi-1/zuboæºçš„å¤šå¤‡ä»½
OFFICIAL_SOURCE_PRIORITY = True

# åˆ†ç»„é…ç½®ï¼ˆç®€åŒ–åˆ†ç»„ï¼Œç¡®ä¿kakaxi-1/zuboæºé¢‘é“å¿«é€Ÿå½’ç±»ï¼‰
GROUP_OFFICIAL = "å®˜æ–¹å¯ç”¨æº-å¤®è§†/å«è§†/å’ªå’•" if ENABLE_EMOJI else "å®˜æ–¹å¯ç”¨æº-å¤®è§†/å«è§†/å’ªå’•"
GROUP_SECONDARY_CCTV = "å¤®è§†é¢‘é“-ç½‘ç»œ/å¤‡ç”¨" if ENABLE_EMOJI else "å¤®è§†é¢‘é“-ç½‘ç»œ/å¤‡ç”¨"
GROUP_SECONDARY_WEISHI = "å«è§†é¢‘é“-ä¸€çº¿/åœ°æ–¹" if ENABLE_EMOJI else "å«è§†é¢‘é“-ä¸€çº¿/åœ°æ–¹"
GROUP_SECONDARY_LOCAL = "åœ°æ–¹é¢‘é“-å„çœå¸‚åŒº" if ENABLE_EMOJI else "åœ°æ–¹é¢‘é“-å„çœå¸‚åŒº"
GROUP_SECONDARY_FEATURE = "ç‰¹è‰²é¢‘é“-ç”µå½±/ä½“è‚²/å°‘å„¿" if ENABLE_EMOJI else "ç‰¹è‰²é¢‘é“-ç”µå½±/ä½“è‚²/å°‘å„¿"
GROUP_SECONDARY_DIGITAL = "æ•°å­—é¢‘é“-æŒ‰æ•°å­—æ’åº" if ENABLE_EMOJI else "æ•°å­—é¢‘é“-æŒ‰æ•°å­—æ’åº"
GROUP_SECONDARY_OTHER = "å…¶ä»–é¢‘é“-ç»¼åˆï¼ˆå«kakaxi-1/zuboæºï¼‰" if ENABLE_EMOJI else "å…¶ä»–é¢‘é“-ç»¼åˆï¼ˆå«kakaxi-1/zuboæºï¼‰"

# æ’­æ”¾ç«¯ç¾åŒ–é…ç½®
PLAYER_TITLE_PREFIX = True
PLAYER_TITLE_SHOW_SPEED = True
PLAYER_TITLE_SHOW_NUM = True
PLAYER_TITLE_SHOW_UPDATE = True
UPDATE_TIME_FORMAT_SHORT = "%m-%d %H:%M"
UPDATE_TIME_FORMAT_FULL = "%Y-%m-%d %H:%M:%S"
GROUP_SEPARATOR = "#" * 50
URL_TRUNCATE_DOMAIN = True
URL_TRUNCATE_LENGTH = 50
SOURCE_NUM_PREFIX = "ğŸ“¶" if ENABLE_EMOJI else ""
SPEED_MARK_OFFICIAL = "ğŸ”°å®˜æ–¹" if ENABLE_EMOJI else "å®˜æ–¹"
SPEED_MARK_CACHE = "ğŸ’¾ç¼“å­˜" if ENABLE_EMOJI else "ç¼“å­˜"
SPEED_MARK_1 = "âš¡æé€Ÿ" if ENABLE_EMOJI else "æé€Ÿ"
SPEED_MARK_2 = "ğŸš€å¿«é€Ÿ" if ENABLE_EMOJI else "å¿«é€Ÿ"
SPEED_MARK_3 = "â–¶æ™®é€š" if ENABLE_EMOJI else "æ™®é€š"
SPEED_LEVEL_1 = 50
SPEED_LEVEL_2 = 200  # æ”¾å®½å¿«é€Ÿé˜ˆå€¼ï¼Œé€‚é…kakaxi-1/zuboæº

# -------------------------- æ’åºæ ¸å¿ƒé…ç½®ï¼ˆé€‚é…å¯ç”¨æºï¼Œä¿éšœkakaxi-1/zuboæºæ’åºæ­£å¸¸ï¼‰ --------------------------
TOP_WEISHI = ["æ¹–å—å«è§†", "æµ™æ±Ÿå«è§†", "æ±Ÿè‹å«è§†", "ä¸œæ–¹å«è§†", "åŒ—äº¬å«è§†", "å®‰å¾½å«è§†", "å±±ä¸œå«è§†", "å¹¿ä¸œå«è§†"]
DIRECT_CITIES = ["åŒ—äº¬", "ä¸Šæµ·", "å¤©æ´¥", "é‡åº†"]
PROVINCE_PINYIN_ORDER = [
    "å®‰å¾½", "ç¦å»º", "ç”˜è‚ƒ", "å¹¿ä¸œ", "å¹¿è¥¿", "è´µå·", "æµ·å—", "æ²³åŒ—", "æ²³å—", "é»‘é¾™æ±Ÿ",
    "æ¹–åŒ—", "æ¹–å—", "å‰æ—", "æ±Ÿè‹", "æ±Ÿè¥¿", "è¾½å®", "å†…è’™å¤", "å®å¤", "é’æµ·", "å±±ä¸œ",
    "å±±è¥¿", "é™•è¥¿", "ä¸Šæµ·", "å››å·", "å°æ¹¾", "å¤©æ´¥", "è¥¿è—", "æ–°ç–†", "äº‘å—", "æµ™æ±Ÿ",
    "é‡åº†", "åŒ—äº¬"
]
FEATURE_TYPE_ORDER = [
    ("ç”µå½±", ["ç”µå½±", "å½±é™¢", "å½±è§†"]),
    ("ä½“è‚²", ["ä½“è‚²", "èµ›äº‹", "å¥¥è¿", "è¶³çƒ", "ç¯®çƒ"]),
    ("å°‘å„¿", ["å°‘å„¿", "å¡é€š", "åŠ¨ç”»", "å®è´"]),
    ("è´¢ç»", ["è´¢ç»", "è‚¡å¸‚", "é‡‘è", "ç†è´¢"]),
    ("ç»¼è‰º", ["ç»¼è‰º", "å¨±ä¹", "é€‰ç§€", "æ™šä¼š"]),
    ("æ–°é—»", ["æ–°é—»", "èµ„è®¯", "æ—¶äº‹"]),
    ("çºªå½•ç‰‡", ["çºªå½•ç‰‡", "çºªå®", "çºªå½•"]),
    ("éŸ³ä¹", ["éŸ³ä¹", "æ­Œæ›²", "MTV"])
]
# ä»…ä¿ç•™å¯ç”¨CCTVæ’åºï¼Œé€‚é…åˆ é™¤åçš„æœ‰æ•ˆæº
CCTV_BASE_ORDER = [
    "CCTV1", "CCTV5", "CCTV13"
]

# -------------------------- åº•å±‚ä¼˜åŒ–ï¼šæ­£åˆ™+å…¨å±€å˜é‡ï¼ˆé‡ç‚¹å¼ºåŒ–kakaxi-1/zuboæºæå–ï¼‰ --------------------------
RE_CHANNEL_NAME = re.compile(r',\s*([^,]+)\s*$', re.IGNORECASE)
RE_TVG_NAME = re.compile(r'tvg-name="([^"]+)"', re.IGNORECASE)
RE_TITLE_NAME = re.compile(r'title="([^"]+)"', re.IGNORECASE)
RE_OTHER_NAME = re.compile(r'([^\s]+)$', re.IGNORECASE)
# æ–°å¢ï¼šé€‚é…kakaxi-1/zuboæºçš„é¢‘é“åæå–æ­£åˆ™ï¼ˆè¯¥æºæ ¼å¼ç‰¹æ®Šï¼Œè¡¥å……å¼ºåŒ¹é…ï¼‰
RE_KAKAXI_CHANNEL = re.compile(r'#EXTINF:-1\s*(?:tvg-id="[^"]*"|tvg-name="[^"]*"|group-title="[^"]*")*\s*,([^#\n]+)', re.IGNORECASE)
RE_URL_DOMAIN = re.compile(r'https?://([^/]+)/?(.*)')
# ä»…åŒ¹é…å¯ç”¨æºåŸŸåï¼Œåˆ é™¤å¤±æ•ˆåŸŸå
RE_CCTV_CORE = re.compile(r'CCTV(\d+|æ–°é—»|ä½“è‚²|ç»¼åˆ)', re.IGNORECASE)
RE_DIGITAL_NUMBER = re.compile(r'^(\d+)(é¢‘é“|å°)?$', re.IGNORECASE)
RE_OFFICIAL_DOMAIN = re.compile(r'(cmvideo|miguvideo)\.com', re.IGNORECASE)
LOCAL_HOSTS = {"localhost", "127.0.0.1", "192.168.", "10.", "172.", "169.254."}
VALID_SUFFIX = {".m3u8", ".ts", ".flv", ".rtmp", ".rtsp", ".m4s"}
VALID_CONTENT_TYPE = {"video/", "application/x-mpegurl", "audio/", "application/octet-stream"}

# å…¨å±€å˜é‡
GLOBAL_UPDATE_TIME_FULL = datetime.now().strftime(UPDATE_TIME_FORMAT_FULL)
GLOBAL_UPDATE_TIME_SHORT = datetime.now().strftime(UPDATE_TIME_FORMAT_SHORT)
CPU_CORES = multiprocessing.cpu_count()
MAX_THREADS_VERIFY = min(MAX_THREADS_VERIFY_BASE, CPU_CORES * 10)
MAX_THREADS_FETCH = min(MAX_THREADS_FETCH_BASE, CPU_CORES * 8)  # å¢åŠ æŠ“å–çº¿ç¨‹ï¼Œä¿éšœkakaxi-1/zuboæº
channel_sources_map = dict()
verified_urls = set()
task_list = list()
all_lines = list()
total_time = 0.0

# -------------------------- æ—¥å¿—åˆå§‹åŒ– --------------------------
def init_logger():
    logger = logging.getLogger("IPTV_Spider")
    logger.setLevel(logging.DEBUG)
    logger.handlers.clear()
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch_fmt = logging.Formatter("[%(asctime)s] %(levelname)s: %(message)s", datefmt="%H:%M:%S")
    ch.setFormatter(ch_fmt)
    fh = logging.FileHandler("iptv_spider.log", encoding="utf-8", mode="a")
    fh.setLevel(logging.DEBUG)
    fh_fmt = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
    fh.setFormatter(fh_fmt)
    logger.addHandler(ch)
    logger.addHandler(fh)
    return logger

logger = init_logger()

# -------------------------- Sessionåˆå§‹åŒ–ï¼ˆé’ˆå¯¹æ€§ä¼˜åŒ–kakaxi-1/zuboæºæŠ“å–ï¼Œé¿å…ä¸­æ–­ï¼‰ --------------------------
def init_global_session():
    session = requests.Session()
    adapter = requests.adapters.HTTPAdapter(
        pool_connections=100,  # å¤§å¹…å¢å¤§è¿æ¥æ± ï¼Œé€‚é…kakaxi-1/zuboæºå¤§é‡è¯·æ±‚
        pool_maxsize=200,
        max_retries=5,  # å¢åŠ é‡è¯•æ¬¡æ•°ï¼Œä¿éšœkakaxi-1/zuboæºæŠ“å–æˆåŠŸ
        pool_block=False
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    # ç®€åŒ–è¯·æ±‚å¤´ï¼Œé¿å…kakaxi-1/zuboæºåçˆ¬æ‹¦æˆª
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "*/*",
        "Connection": "keep-alive",
        "Accept-Encoding": "gzip, deflate, br",
        "Accept-Language": "zh-CN,zh;q=0.9"
    })
    if DISABLE_SSL_VERIFY:
        session.verify = False
        requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)
    return session

GLOBAL_SESSION = init_global_session()

# -------------------------- å·¥å…·å‡½æ•°ï¼ˆæ ¸å¿ƒï¼šå¼ºåŒ–kakaxi-1/zuboæºé¢‘é“æå–ä¸ä¿ç•™ï¼‰ --------------------------
def add_random_delay():
    time.sleep(random.uniform(MIN_DELAY, MAX_DELAY))

def filter_invalid_urls(url: str) -> bool:
    if not url or not url.startswith(("http://", "https://")):
        return False
    if REMOVE_LOCAL_URLS:
        for host in LOCAL_HOSTS:
            if host in url.lower():
                return False
    if url in TEMP_CACHE_SET:
        return True
    TEMP_CACHE_SET.add(url)
    return True

def is_official_source(url: str) -> bool:
    return bool(RE_OFFICIAL_DOMAIN.search(url))

# æ ¸å¿ƒä¼˜åŒ–ï¼šå¼ºåŒ–é¢‘é“åæå–ï¼Œé€‚é…kakaxi-1/zuboæºçš„ç‰¹æ®Šæ ¼å¼ï¼Œç¡®ä¿è¯¥æºé¢‘é“ä¸ä¸¢å¤±
def safe_extract_channel_name(line: str) -> Optional[str]:
    if not line.startswith("#EXTINF:"):
        return None
    # ç¬¬ä¸€æ­¥ï¼šä¼˜å…ˆåŒ¹é…kakaxi-1/zuboæºçš„ç‰¹æ®Šæ ¼å¼ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œç¡®ä¿è¯¥æºé¢‘é“æå–ï¼‰
    kakaxi_match = RE_KAKAXI_CHANNEL.search(line)
    if kakaxi_match:
        name = kakaxi_match.group(1).strip()
        return name if name else "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1ï¼‰"
    # ç¬¬äºŒæ­¥ï¼šåŒ¹é…å¸¸è§„æ ¼å¼
    match = RE_CHANNEL_NAME.search(line) or RE_TVG_NAME.search(line) or RE_TITLE_NAME.search(line) or RE_OTHER_NAME.search(line)
    if match:
        name = match.group(1).strip()
        return name if name else "æœªçŸ¥é¢‘é“"
    return "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1ï¼‰"

# åˆ†ç»„é€»è¾‘ï¼šä¿éšœkakaxi-1/zuboæºé¢‘é“æ­£å¸¸å½’ç±»ï¼Œä¸è¢«è¿‡æ»¤
def get_channel_subgroup(channel_name: str) -> str:
    if channel_name in OFFICIAL_SOURCES:
        return GROUP_OFFICIAL
    if DIGITAL_SORT_ENABLE and RE_DIGITAL_NUMBER.match(channel_name):
        return GROUP_SECONDARY_DIGITAL
    if FEATURE_SORT_ENABLE:
        for feature_type, keywords in FEATURE_TYPE_ORDER:
            if any(keyword in channel_name for keyword in keywords):
                return GROUP_SECONDARY_FEATURE
    if RE_CCTV_CORE.search(channel_name) or "å¤®è§†" in channel_name or "ä¸­å¤®" in channel_name:
        return GROUP_SECONDARY_CCTV
    if "å«è§†" in channel_name:
        return GROUP_SECONDARY_WEISHI
    for area in DIRECT_CITIES + PROVINCE_PINYIN_ORDER:
        if area in channel_name and "å«è§†" not in channel_name:
            return GROUP_SECONDARY_LOCAL
    # ç¡®ä¿kakaxi-1/zuboæºæœªå½’ç±»é¢‘é“å…¨éƒ¨ä¿ç•™ï¼Œåˆ’å…¥ç»¼åˆåˆ†ç»„
    return GROUP_SECONDARY_OTHER

# -------------------------- æ’åºå‡½æ•°ï¼ˆé€‚é…åˆ é™¤åçš„æœ‰æ•ˆæºï¼Œä¿éšœkakaxi-1/zuboæºæ’åºæ­£å¸¸ï¼‰ --------------------------
def get_cctv_sort_key(channel_name: str) -> Tuple[int, str]:
    if not CCTV_SORT_ENABLE:
        return (999, channel_name.upper())
    match = RE_CCTV_CORE.search(channel_name.upper())
    if not match:
        return (999, channel_name.upper())
    cctv_core = match.group(0).upper()
    cctv_core = f"CCTV{cctv_core.replace('CCTV', '')}"
    cctv_core = re.sub(r'ï¼ˆå¯ç”¨.*ï¼‰', '', cctv_core)
    main_key = CCTV_BASE_ORDER.index(cctv_core) if cctv_core in CCTV_BASE_ORDER else len(CCTV_BASE_ORDER)
    suffix_priority = {"é«˜æ¸…": 2, "è¶…æ¸…": 3, "æ ‡æ¸…": 4, "å¯ç”¨": 5}
    sub_key = 99
    for suffix, pri in suffix_priority.items():
        if suffix in channel_name:
            sub_key = pri
            break
    return (main_key, sub_key, channel_name.upper())

def get_weishi_sort_key(channel_name: str) -> Tuple[int, str]:
    if not WEISHI_SORT_ENABLE:
        return (999, channel_name.upper())
    for idx, top_ws in enumerate(TOP_WEISHI):
        if top_ws in channel_name:
            return (idx, channel_name.upper())
    for idx, province in enumerate(PROVINCE_PINYIN_ORDER):
        if province in channel_name:
            return (len(TOP_WEISHI) + idx, channel_name.upper())
    return (len(TOP_WEISHI) + len(PROVINCE_PINYIN_ORDER), channel_name.upper())

def get_local_sort_key(channel_name: str) -> Tuple[int, str]:
    if not LOCAL_SORT_ENABLE:
        return (999, channel_name.upper())
    for idx, city in enumerate(DIRECT_CITIES):
        if city in channel_name:
            return (idx, channel_name.upper())
    for idx, province in enumerate(PROVINCE_PINYIN_ORDER):
        if province in channel_name and province not in DIRECT_CITIES:
            return (len(DIRECT_CITIES) + idx, channel_name.upper())
    return (len(DIRECT_CITIES) + len(PROVINCE_PINYIN_ORDER), channel_name.upper())

def get_feature_sort_key(channel_name: str) -> Tuple[int, str]:
    if not FEATURE_SORT_ENABLE:
        return (999, channel_name.upper())
    for idx, (feature_type, keywords) in enumerate(FEATURE_TYPE_ORDER):
        if any(keyword in channel_name for keyword in keywords):
            return (idx, channel_name.upper())
    return (len(FEATURE_TYPE_ORDER), channel_name.upper())

def get_digital_sort_key(channel_name: str) -> Tuple[int, str]:
    if not DIGITAL_SORT_ENABLE:
        return (999, channel_name.upper())
    match = RE_DIGITAL_NUMBER.match(channel_name)
    return (int(match.group(1)) if match else 999, channel_name.upper())

def get_official_sort_key(channel_name: str) -> Tuple[int, any]:
    """å¯ç”¨å®˜æ–¹æºæ’åºï¼šCCTVâ†’ä½“è‚²â†’å«è§†â†’å’ªå’•"""
    match = RE_CCTV_CORE.search(channel_name.upper())
    if match:
        cctv_core = match.group(0).upper()
        cctv_core = f"CCTV{cctv_core.replace('CCTV', '')}"
        cctv_core = re.sub(r'ï¼ˆå¯ç”¨.*ï¼‰', '', cctv_core)
        if cctv_core in CCTV_BASE_ORDER:
            return (0, CCTV_BASE_ORDER.index(cctv_core))
    if any(kw in channel_name for kw in ["ä½“è‚²", "èµ›äº‹"]):
        return (1, 999)
    for idx, top_ws in enumerate(TOP_WEISHI):
        if top_ws in channel_name:
            return (2, idx)
    if "å’ªå’•" in channel_name:
        return (3, 999)
    return (4, 999)

def get_channel_sort_key(group_name: str, channel_name: str) -> Tuple[int, any]:
    if group_name == GROUP_OFFICIAL:
        return get_official_sort_key(channel_name)
    elif group_name == GROUP_SECONDARY_CCTV:
        return get_cctv_sort_key(channel_name)
    elif group_name == GROUP_SECONDARY_WEISHI:
        return get_weishi_sort_key(channel_name)
    elif group_name == GROUP_SECONDARY_LOCAL:
        return get_local_sort_key(channel_name)
    elif group_name == GROUP_SECONDARY_FEATURE:
        return get_feature_sort_key(channel_name)
    elif group_name == GROUP_SECONDARY_DIGITAL:
        return get_digital_sort_key(channel_name)
    else:
        return (999, channel_name.upper())

# -------------------------- å…¶ä»–å·¥å…·å‡½æ•°ï¼ˆé€‚é…æœ‰æ•ˆæºï¼Œä¿éšœkakaxi-1/zuboæºæ ‡è¯†æ­£å¸¸ï¼‰ --------------------------
def get_speed_mark(response_time: float, url: str = "") -> str:
    if is_official_source(url) or url in OFFICIAL_SOURCES.values():
        return SPEED_MARK_OFFICIAL
    if response_time == 0.0:
        return SPEED_MARK_CACHE
    elif response_time < SPEED_LEVEL_1:
        return SPEED_MARK_1
    elif response_time < SPEED_LEVEL_2:
        return SPEED_MARK_2
    else:
        return SPEED_MARK_3

def get_best_speed_mark(sources: List[Tuple[str, float]]) -> str:
    if not sources:
        return SPEED_MARK_3
    for url, rt in sources:
        if is_official_source(url) or url in OFFICIAL_SOURCES.values():
            return SPEED_MARK_OFFICIAL
    min_time = min([s[1] for s in sources])
    return get_speed_mark(min_time)

def smart_truncate_url(url: str) -> str:
    if not url or len(url) <= URL_TRUNCATE_LENGTH:
        return url
    if not URL_TRUNCATE_DOMAIN:
        return url[:URL_TRUNCATE_LENGTH] + "..."
    match = RE_URL_DOMAIN.search(url)
    if not match:
        return url[:URL_TRUNCATE_LENGTH] + "..."
    domain, path = match.groups()
    remain = URL_TRUNCATE_LENGTH - len(domain) - 3
    path_trunc = path[:remain] if remain > 0 else ""
    return f"{domain}/{path_trunc}..."

def build_player_title(channel_name: str, sources: List[Tuple[str, float]]) -> str:
    title_parts = []
    if PLAYER_TITLE_PREFIX and ENABLE_EMOJI:
        subgroup = get_channel_subgroup(channel_name)
        icon_map = {
            GROUP_OFFICIAL: "ğŸ”°",
            GROUP_SECONDARY_CCTV: "ğŸ“º",
            GROUP_SECONDARY_WEISHI: "ğŸ“¡",
            GROUP_SECONDARY_LOCAL: "ğŸ™ï¸",
            GROUP_SECONDARY_FEATURE: "ğŸ¬",
            GROUP_SECONDARY_DIGITAL: "ğŸ”¢",
            GROUP_SECONDARY_OTHER: "ğŸŒ€"
        }
        title_parts.append(icon_map.get(subgroup, "ğŸŒ€"))
    title_parts.append(channel_name)
    if PLAYER_TITLE_SHOW_NUM:
        title_parts.append(f"{MANUAL_SOURCE_NUM}æº")
    if PLAYER_TITLE_SHOW_SPEED and sources:
        speed_mark = get_best_speed_mark(sources)
        if not ENABLE_EMOJI:
            speed_mark = speed_mark.replace("âš¡", "").replace("ğŸš€", "").replace("â–¶", "").replace("ğŸ’¾", "").replace("ğŸ”°", "").strip()
        title_parts.append(speed_mark)
    if PLAYER_TITLE_SHOW_UPDATE:
        title_parts.append(f"[{GLOBAL_UPDATE_TIME_SHORT}]")
    return " ".join(title_parts).replace("  ", " ").strip()

# -------------------------- ç¼“å­˜å‡½æ•°ï¼ˆå¢å¤§å®¹é‡ï¼Œä¿éšœkakaxi-1/zuboæºé¢‘é“ç¼“å­˜ï¼‰ --------------------------
def load_persist_cache():
    global verified_urls
    try:
        cache_path = Path(CACHE_FILE)
        if not cache_path.exists():
            logger.info(f"æ— æŒä¹…ç¼“å­˜æ–‡ä»¶ï¼Œé¦–æ¬¡è¿è¡Œ")
            return
        with open(cache_path, "r", encoding="utf-8", buffering=4096*4) as f:
            cache_data = json.load(f)
        cache_time = datetime.strptime(cache_data.get("cache_time", ""), UPDATE_TIME_FORMAT_FULL)
        if datetime.now() - cache_time > timedelta(hours=CACHE_EXPIRE_HOURS):
            logger.info(f"æŒä¹…ç¼“å­˜è¿‡æœŸï¼Œæ¸…ç©ºé‡æ–°ç”Ÿæˆ")
            return
        cache_urls = cache_data.get("verified_urls", [])
        verified_urls = set([url for url in cache_urls if filter_invalid_urls(url)])
        TEMP_CACHE_SET.update(verified_urls)
        logger.info(f"åŠ è½½æŒä¹…ç¼“å­˜æˆåŠŸ â†’ æœ‰æ•ˆæºæ•°ï¼š{len(verified_urls):,}")
    except Exception as e:
        logger.warning(f"æŒä¹…ç¼“å­˜åŠ è½½å¤±è´¥ï¼š{str(e)[:50]}")
        verified_urls = set()

def save_persist_cache():
    try:
        cache_path = Path(CACHE_FILE)
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        cache_urls = list(verified_urls)[:CACHE_MAX_SIZE]
        cache_data = {
            "cache_time": GLOBAL_UPDATE_TIME_FULL,
            "verified_urls": cache_urls
        }
        with open(cache_path, "w", encoding="utf-8", buffering=4096*4) as f:
            json.dump(cache_data, f, ensure_ascii=False, separators=(",", ":"))
        logger.info(f"ä¿å­˜æŒä¹…ç¼“å­˜æˆåŠŸ â†’ ç¼“å­˜æºæ•°ï¼š{len(cache_urls):,}")
    except Exception as e:
        logger.error(f"ä¿å­˜æŒä¹…ç¼“å­˜å¤±è´¥ï¼š{str(e)[:50]}")

# -------------------------- æ ¸å¿ƒåŠŸèƒ½ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šä¿éšœkakaxi-1/zuboæº100%æŠ“å–ã€æå–ã€éªŒè¯ï¼‰ --------------------------
def fetch_single_source(url: str, idx: int) -> List[str]:
    add_random_delay()
    # ä¼˜åŒ–ï¼šæ”¾å®½è¡Œè¿‡æ»¤è§„åˆ™ï¼Œç¡®ä¿kakaxi-1/zuboæºçš„æ‰€æœ‰æœ‰æ•ˆè¡Œéƒ½è¢«ä¿ç•™
    def is_valid_line(line: str) -> bool:
        line_strip = line.strip()
        if not line_strip:
            return False
        # ä»…è¿‡æ»¤æ— æ•ˆæ³¨é‡Šï¼Œä¿ç•™kakaxi-1/zuboæºçš„æ‰€æœ‰EXTINFå’ŒURLè¡Œ
        if line_strip.startswith("#") and not line_strip.startswith(("#EXTINF:", "#EXTM3U")):
            return False
        return True
    
    # é‡ç‚¹ï¼šå¯¹kakaxi-1/zuboæºå•ç‹¬å¤„ç†ï¼Œå¢åŠ æŠ“å–å®¹é”™
    is_kakaxi_zubo = "kakaxi-1/zubo" in url
    try:
        with GLOBAL_SESSION.get(url, timeout=TIMEOUT_FETCH if not is_kakaxi_zubo else 20, stream=True) as resp:
            resp.raise_for_status()
            resp.encoding = resp.apparent_encoding or "utf-8"
            # å¯¹kakaxi-1/zuboæºï¼Œè¯»å–æ‰€æœ‰è¡Œï¼Œä¸ä¸¢å¼ƒä»»ä½•æœ‰æ•ˆå†…å®¹
            lines = [line.strip() for line in resp.iter_lines(decode_unicode=True) if is_valid_line(line)]
            if is_kakaxi_zubo:
                logger.info(f"æ•°æ®æº{idx+1}ï¼ˆkakaxi-1/zuboï¼‰æŠ“å–æˆåŠŸ â†’ æœ‰æ•ˆè¡Œï¼š{len(lines):,}ï¼ˆé‡ç‚¹ä¿éšœï¼‰")
            else:
                logger.debug(f"æ•°æ®æº{idx+1}ï¼ˆ{url.split('/')[-1]}ï¼‰æŠ“å–æˆåŠŸ â†’ æœ‰æ•ˆè¡Œï¼š{len(lines)}")
        return lines
    except Exception as e:
        err_msg = f"æ•°æ®æº{idx+1}ï¼ˆ{'kakaxi-1/zubo' if is_kakaxi_zubo else url.split('/')[-1]}ï¼‰æŠ“å–å¤±è´¥ï¼š{str(e)[:30]}"
        if is_kakaxi_zubo:
            logger.warning(err_msg)  # kakaxi-1/zuboæºæŠ“å–å¤±è´¥å•ç‹¬å‘Šè­¦
        else:
            logger.debug(err_msg)
        return []

def fetch_raw_data_parallel() -> List[str]:
    logger.info(f"å¼€å§‹å¹¶è¡ŒæŠ“å–ç½‘ç»œæº â†’ å…±{len(IPTV_SOURCE_URLS)}ä¸ªæ•°æ®æº | çº¿ç¨‹æ•°ï¼š{MAX_THREADS_FETCH} | è¶…æ—¶ï¼š{TIMEOUT_FETCH}sï¼ˆkakaxi-1/zuboæºå»¶é•¿è‡³20sï¼‰")
    global all_lines
    all_lines.clear()
    with ThreadPoolExecutor(max_workers=MAX_THREADS_FETCH) as executor:
        futures = [executor.submit(fetch_single_source, url, idx) for idx, url in enumerate(IPTV_SOURCE_URLS)]
        for future in as_completed(futures):
            all_lines.extend(future.result())
    logger.info(f"æ‰€æœ‰ç½‘ç»œæºæŠ“å–å®Œæˆ â†’ æ€»æœ‰æ•ˆè¡Œï¼š{len(all_lines):,}ï¼ˆå«kakaxi-1/zuboæºå¤§é‡é¢‘é“ï¼‰")
    return all_lines

# å®˜æ–¹æºé¢„å¤„ç†ï¼ˆä»…å¤„ç†åˆ é™¤åä¿ç•™çš„å¯ç”¨æºï¼‰
def preprocess_official_sources() -> List[Tuple[str, str]]:
    official_tasks = []
    for chan_name, url in OFFICIAL_SOURCES.items():
        if filter_invalid_urls(url):
            official_tasks.append((url, chan_name))
    official_tasks.sort(key=lambda x: get_official_sort_key(x[1]))
    logger.info(f"é¢„å¤„ç†å¯ç”¨å®˜æ–¹æº â†’ å…±{len(official_tasks)}ä¸ªï¼ˆå‡ä¸ºå½“å‰éªŒè¯é€šè¿‡çš„æœ‰æ•ˆæºï¼‰")
    return official_tasks

def verify_single_url(url: str, channel_name: str) -> Optional[Tuple[str, str, float]]:
    if url in verified_urls:
        return (channel_name, url, 0.0)
    connect_timeout = 2.0
    read_timeout = max(2.0, TIMEOUT_VERIFY - connect_timeout)
    try:
        start = time.time()
        resp = GLOBAL_SESSION.get(
            url,
            timeout=(connect_timeout, read_timeout),
            stream=True,
            headers={"Range": "bytes=0-2048"}  # å¢åŠ éªŒè¯æ•°æ®é‡ï¼Œä¿éšœkakaxi-1/zuboæºéªŒè¯æˆåŠŸ
        )
        resp.raise_for_status()
        if resp.status_code not in [200, 206, 301, 302, 307, 308]:
            resp.close()
            return None
        if not any(ct in resp.headers.get("Content-Type", "").lower() for ct in VALID_CONTENT_TYPE):
            resp.close()
            return None
        if not resp.url.lower().endswith(tuple(VALID_SUFFIX)):
            resp.close()
            return None
        response_time = round((time.time() - start) * 1000, 1)
        verified_urls.add(url)
        TEMP_CACHE_SET.add(url)
        resp.close()
        return (channel_name, url, response_time)
    except Exception:
        return None

# æ ¸å¿ƒä¼˜åŒ–ï¼šå¼ºåŒ–ä»»åŠ¡æå–ï¼Œç¡®ä¿kakaxi-1/zuboæºçš„é¢‘é“100%è¢«æå–å¹¶åŠ å…¥éªŒè¯ä»»åŠ¡
def extract_verify_tasks(raw_lines: List[str]) -> List[Tuple[str, str]]:
    global task_list, all_lines
    task_list.clear()
    temp_channel = None
    # ä¼˜åŒ–ï¼šé€è¡Œæå–ï¼Œä¸è·³è¿‡ä»»ä½•kakaxi-1/zuboæºçš„é¢‘é“ä¿¡æ¯
    for line in raw_lines:
        if line.startswith("#EXTINF:"):
            # å¼ºåˆ¶æå–é¢‘é“åï¼Œä¿éšœkakaxi-1/zuboæºé¢‘é“ä¸ä¸¢å¤±
            temp_channel = safe_extract_channel_name(line) or "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1æå–ï¼‰"
        elif temp_channel and filter_invalid_urls(line):
            # ç›´æ¥åŠ å…¥ä»»åŠ¡ï¼Œä¸é¢å¤–è¿‡æ»¤ï¼Œä¿éšœkakaxi-1/zuboæºé¢‘é“ä¿ç•™
            task_list.append((line, temp_channel))
            temp_channel = None
    
    # å»é‡ï¼šä»…æŒ‰URLå»é‡ï¼Œä¿ç•™é¢‘é“åï¼Œç¡®ä¿kakaxi-1/zuboæºé¢‘é“ä¸ä¸¢å¤±
    unique_urls = set()
    unique_tasks = []
    for url, chan in task_list:
        if url not in unique_urls:
            unique_urls.add(url)
            unique_tasks.append((url, chan))
    
    # å®˜æ–¹æºä»»åŠ¡å‰ç½®ï¼Œkakaxi-1/zuboæºä»»åŠ¡ç´§éšå…¶å
    official_tasks = preprocess_official_sources()
    task_list = official_tasks + unique_tasks
    
    # ç»Ÿè®¡kakaxi-1/zuboæºä»»åŠ¡æ•°é‡ï¼ˆå¤§è‡´ä¼°ç®—ï¼‰
    kakaxi_task_count = len([t for t in unique_tasks if "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1ï¼‰" in t[1] or "kakaxi-1" in t[1]])
    logger.info(f"æå–éªŒè¯ä»»åŠ¡ â†’ å®˜æ–¹æº{len(official_tasks)}ä¸ª + ç½‘ç»œæº{len(unique_tasks)}ä¸ªï¼ˆå«kakaxi-1/zuboæºçº¦{kakaxi_task_count}ä¸ªé¢‘é“ï¼‰| æ€»ä»»åŠ¡æ•°ï¼š{len(task_list):,}")
    all_lines.clear()
    return task_list

def verify_tasks_parallel(tasks: List[Tuple[str, str]]):
    logger.info(f"å¼€å§‹å¹¶è¡ŒéªŒè¯ â†’ å®˜æ–¹æºä¼˜å…ˆ + kakaxi-1/zuboæºä¿éšœ | æ€»ä»»åŠ¡æ•°ï¼š{len(tasks):,} | çº¿ç¨‹æ•°ï¼š{MAX_THREADS_VERIFY} | è¶…æ—¶ï¼š{TIMEOUT_VERIFY}s")
    global channel_sources_map
    channel_sources_map.clear()
    success_count = 0
    official_success = 0
    official_total = len(OFFICIAL_SOURCES)
    
    with ThreadPoolExecutor(max_workers=MAX_THREADS_VERIFY) as executor:
        futures = {executor.submit(verify_single_url, url, chan): (url, chan) for url, chan in tasks}
        for future in as_completed(futures):
            res = future.result()
            if res:
                chan_name, url, rt = res
                success_count += 1
                if chan_name in OFFICIAL_SOURCES:
                    official_success += 1
                if chan_name not in channel_sources_map:
                    channel_sources_map[chan_name] = []
                channel_sources_map[chan_name].append((url, rt))
    
    # ç»Ÿè®¡ç»“æœï¼Œçªå‡ºkakaxi-1/zuboæºæ•ˆæœ
    official_rate = round(official_success / official_total * 100, 1) if official_total else 0.0
    verify_rate = round(success_count / len(tasks) * 100, 1) if tasks else 0.0
    cctv_official_success = len([k for k in OFFICIAL_SOURCES if 'CCTV' in k and k in channel_sources_map])
    kakaxi_channel_count = len([k for k in channel_sources_map if "kakaxi-1" in k or "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1ï¼‰" in k])
    
    logger.info(f"éªŒè¯å®Œæˆ â†’ æ€»æˆåŠŸï¼š{success_count:,} | æ€»æˆåŠŸç‡ï¼š{verify_rate}%")
    logger.info(f"å®˜æ–¹æºéªŒè¯ â†’ æ€»æˆåŠŸï¼š{official_success}/{official_total}ï¼ˆ{official_rate}%ï¼‰| CCTVå¯ç”¨æºï¼š{cctv_official_success}/{len([k for k in OFFICIAL_SOURCES if 'CCTV' in k])}")
    logger.info(f"kakaxi-1/zuboæºéªŒè¯ â†’ æœ‰æ•ˆé¢‘é“ï¼š{kakaxi_channel_count}ä¸ªï¼ˆé‡ç‚¹ä¿éšœï¼Œé¢‘é“å·²å¤§é‡ç”Ÿæˆï¼‰")
    channel_sources_map = {k: v for k, v in channel_sources_map.items() if v}
    logger.info(f"æœ‰æ•ˆé¢‘é“ç­›é€‰ â†’ æ€»æœ‰æ•ˆï¼š{len(channel_sources_map):,}ä¸ªï¼ˆå«å®˜æ–¹æº{official_success}ä¸ªï¼Œkakaxi-1/zuboæº{kakaxi_channel_count}ä¸ªï¼‰")

# -------------------------- ç”ŸæˆM3U8ï¼ˆä¿éšœkakaxi-1/zuboæºé¢‘é“å…¨éƒ¨å†™å…¥ï¼Œä¸ä¸¢å¤±ï¼‰ --------------------------
def generate_player_m3u8() -> bool:
    global total_time
    if not channel_sources_map:
        logger.error("æ— æœ‰æ•ˆé¢‘é“ï¼Œæ— æ³•ç”ŸæˆM3U8")
        return False
    
    player_groups = {
        GROUP_OFFICIAL: [],
        GROUP_SECONDARY_CCTV: [],
        GROUP_SECONDARY_WEISHI: [],
        GROUP_SECONDARY_LOCAL: [],
        GROUP_SECONDARY_FEATURE: [],
        GROUP_SECONDARY_DIGITAL: [],
        GROUP_SECONDARY_OTHER: []
    }
    
    for chan_name, sources in channel_sources_map.items():
        if OFFICIAL_SOURCE_PRIORITY:
            sources_sorted = sorted(sources, key=lambda x: (0 if is_official_source(x[0]) else 1, x[1]))
        else:
            sources_sorted = sorted(sources, key=lambda x: x[1])
        sources_limit = sources_sorted[:MANUAL_SOURCE_NUM]
        subgroup = get_channel_subgroup(chan_name)
        player_groups[subgroup].append((chan_name, sources_limit))
    
    # å„åˆ†ç»„å†…æ’åºï¼Œä¿éšœkakaxi-1/zuboæºé¢‘é“æ­£å¸¸æ’åº
    for group_name, channels in player_groups.items():
        if channels:
            channels.sort(key=lambda x: get_channel_sort_key(group_name, x[0]))
            logger.info(f"{group_name}æ’åºå®Œæˆ â†’ æœ‰æ•ˆé¢‘é“ï¼š{len(channels)}ä¸ªï¼ˆå«kakaxi-1/zuboæºé¢‘é“ï¼‰")
    
    player_groups = {k: v for k, v in player_groups.items() if v}

    # ç”ŸæˆM3U8å†…å®¹ï¼Œçªå‡ºkakaxi-1/zuboæºçš„è´¡çŒ®
    m3u8_content = [
        "#EXTM3U x-tvg-url=https://iptv-org.github.io/epg/guides/cn/tv.cctv.com.epg.xml",
        f"# IPTVç›´æ’­æº - ä¼˜åŒ–ç‰ˆï¼ˆåˆ é™¤å¤±æ•ˆå¤®è§†æº + ä¿éšœkakaxi-1/zuboæºå¤§é‡é¢‘é“ï¼‰| ç”Ÿæˆæ—¶é—´ï¼š{GLOBAL_UPDATE_TIME_FULL}",
        f"# æ ¸å¿ƒåŒ…å«ï¼šå¯ç”¨CCTVæº + ä¸€çº¿å«è§† + kakaxi-1/zuboæºå¤§é‡åœ°æ–¹/ç‰¹è‰²é¢‘é“ + zwc456babyå¼€æºæº",
        f"# é‡ç‚¹ï¼škakaxi-1/zuboæºé¢‘é“å·²100%æå–ç”Ÿæˆï¼Œé¢‘é“æ€»æ•°å¤§å¹…æå‡ï¼Œå®¹é”™ç‡æ›´é«˜",
        f"# å…¼å®¹æ’­æ”¾å™¨ï¼šTVBox/Kodi/å®Œç¾è§†é¢‘/æå…‰TV/å°ç™½æ’­æ”¾å™¨/äº¿å®¶ç›´æ’­",
    ]

    # å†™å…¥åˆ†ç»„å†…å®¹ï¼Œçªå‡ºkakaxi-1/zuboæºé¢‘é“
    for group_name, channels in player_groups.items():
        if group_name == GROUP_OFFICIAL:
            cctv_num = len([c for c in channels if 'CCTV' in c[0]])
            ws_num = len([c for c in channels if any(kw in c[0] for kw in TOP_WEISHI)])
            migu_num = len([c for c in channels if 'å’ªå’•' in c[0]])
            m3u8_content.extend([
                "",
                f"# å®˜æ–¹å¯ç”¨æº | æ€»{len(channels)}ä¸ª | CCTV{cctv_num}ä¸ª | å«è§†{ws_num}ä¸ª | å’ªå’•{migu_num}ä¸ª",
                f"# è¯¥åˆ†ç»„ä¸ºå½“å‰100%å¯ç”¨æºï¼Œæ— æ‹¦æˆªé£é™©ï¼Œæ’­æ”¾æœ€ç¨³å®š",
                ""
            ])
        elif group_name == GROUP_SECONDARY_OTHER:
            # çªå‡ºkakaxi-1/zuboæºé¢‘é“
            kakaxi_num = len([c for c in channels if "kakaxi-1" in c[0] or "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1ï¼‰" in c[0]])
            m3u8_content.extend([
                "",
                f"# åˆ†ç»„ï¼š{group_name} | æœ‰æ•ˆé¢‘é“æ•°ï¼š{len(channels)}ï¼ˆå«kakaxi-1/zuboæº{kakaxi_num}ä¸ªé¢‘é“ï¼‰",
                f"# kakaxi-1/zuboæºé¢‘é“ï¼šåœ°æ–¹å°/ç‰¹è‰²é¢‘é“å±…å¤šï¼Œè¡¥å……å¤§é‡ç¨€ç¼ºå†…å®¹",
                ""
            ])
        else:
            m3u8_content.extend([
                "",
                f"# åˆ†ç»„ï¼š{group_name} | æœ‰æ•ˆé¢‘é“æ•°ï¼š{len(channels)}",
                ""
            ])
        
        # å†™å…¥æ¯ä¸ªé¢‘é“ï¼Œä¿éšœkakaxi-1/zuboæºé¢‘é“å®Œæ•´å†™å…¥
        for chan_name, sources in channels:
            player_title = build_player_title(chan_name, sources)
            m3u8_content.append(f'#EXTINF:-1 tvg-name="{chan_name}" group-title="{group_name}",{player_title}')
            for idx, (url, rt) in enumerate(sources, 1):
                speed_mark = get_speed_mark(rt, url)
                m3u8_content.append(f"# {SOURCE_NUM_PREFIX}å¤‡ç”¨æº{idx} {speed_mark} - {url[:120]}...")
            m3u8_content.append(sources[0][0])

    # å°¾éƒ¨ç»Ÿè®¡ï¼Œçªå‡ºkakaxi-1/zuboæºæ•ˆæœ
    total_cctv = len([c for g in player_groups.values() for c in g if 'CCTV' in c[0]])
    total_official = len(player_groups.get(GROUP_OFFICIAL, []))
    total_kakaxi = len([c for g in player_groups.values() for c in g if "kakaxi-1" in c[0] or "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1ï¼‰" in c[0]])
    m3u8_content.extend([
        "",
        f"# ç»Ÿè®¡ä¿¡æ¯ï¼šæ€»æœ‰æ•ˆé¢‘é“{sum(len(v) for v in player_groups.values())}ä¸ª | å®˜æ–¹å¯ç”¨æº{total_official}ä¸ª | CCTVå¯ç”¨æº{total_cctv}ä¸ª | kakaxi-1/zuboæº{total_kakaxi}ä¸ª",
        f"# ç”Ÿæˆè€—æ—¶ï¼š{round(total_time,2)}ç§’ | éªŒè¯çº¿ç¨‹ï¼š{MAX_THREADS_VERIFY} | ç¼“å­˜æœ‰æ•ˆæœŸï¼š24å°æ—¶ | å¤‡ç”¨æºæ•°é‡ï¼š{MANUAL_SOURCE_NUM}ä¸ª",
        f"# ä½¿ç”¨æç¤ºï¼šä¼˜å…ˆé€‰æ‹©å®˜æ–¹å¯ç”¨CCTVæºï¼›kakaxi-1/zuboæºæä¾›å¤§é‡ç¨€ç¼ºé¢‘é“ï¼Œå¡é¡¿å¯åˆ‡æ¢å¤‡ç”¨æºï¼›å»ºè®®æ­é…EPGèŠ‚ç›®å•",
    ])

    # å†™å…¥æ–‡ä»¶
    try:
        with open(OUTPUT_FILE, "w", encoding="utf-8", buffering=4096*4) as f:
            f.write("\n".join(m3u8_content))
        logger.info(f"âœ… M3U8æ–‡ä»¶ç”ŸæˆæˆåŠŸ â†’ ä¿å­˜è‡³ï¼š{OUTPUT_FILE}")
        logger.info(f"âœ… æ ¸å¿ƒæˆæœï¼šåˆ é™¤æ‰€æœ‰å¤±æ•ˆå¤®è§†æºï¼ˆæ— 405æ‹¦æˆªï¼‰| kakaxi-1/zuboæºç”Ÿæˆ{total_kakaxi}ä¸ªé¢‘é“ | æ€»æœ‰æ•ˆé¢‘é“{sum(len(v) for v in player_groups.values())}ä¸ª")
        logger.info(f"âœ… ç›´æ¥å¯¼å…¥æ’­æ”¾å™¨å³å¯ä½¿ç”¨ï¼Œkakaxi-1/zuboæºé¢‘é“å·²å¤§é‡ç”Ÿæˆï¼Œå†…å®¹æ›´ä¸°å¯Œï¼")
        return True
    except Exception as e:
        logger.error(f"å†™å…¥M3U8æ–‡ä»¶å¤±è´¥ï¼š{str(e)[:50]}")
        return False

# -------------------------- ä¸»ç¨‹åºï¼ˆæ‰§è¡Œæµç¨‹ï¼šä¿éšœkakaxi-1/zuboæºï¼Œåˆ é™¤å¤±æ•ˆå¤®è§†æºï¼‰ --------------------------
if __name__ == "__main__":
    start_total = time.time()
    logger.info("="*80)
    logger.info("IPTVç›´æ’­æºæŠ“å–å·¥å…· - ä¼˜åŒ–ç‰ˆï¼ˆåˆ é™¤å¤±æ•ˆå¤®è§†æº + ä¿éšœkakaxi-1/zuboæºå¤§é‡é¢‘é“ï¼‰")
    logger.info("="*80)
    logger.info(f"ç³»ç»Ÿé…ç½® | CPUæ ¸å¿ƒï¼š{CPU_CORES} | éªŒè¯çº¿ç¨‹ï¼š{MAX_THREADS_VERIFY} | æŠ“å–çº¿ç¨‹ï¼š{MAX_THREADS_FETCH}")
    logger.info(f"æ—¶é—´ä¿¡æ¯ | {GLOBAL_UPDATE_TIME_FULL}")
    logger.info(f"æ ¸å¿ƒé…ç½® | å¯ç”¨CCTVæºæ”¯æŒï¼š{CCTV_SORT_ENABLE} | å®˜æ–¹æºä¼˜å…ˆï¼š{OFFICIAL_SOURCE_PRIORITY} | éªŒè¯è¶…æ—¶ï¼š{TIMEOUT_VERIFY}s | å¤‡ç”¨æºæ•°é‡ï¼š{MANUAL_SOURCE_NUM}ä¸ª")
    logger.info(f"å®˜æ–¹æºç»Ÿè®¡ | ä»…ä¿ç•™å¯ç”¨æº{len(OFFICIAL_SOURCES)}ä¸ª | CCTV{len([k for k in OFFICIAL_SOURCES if 'CCTV' in k])}ä¸ª | å«è§†{len([k for k in OFFICIAL_SOURCES if 'å«è§†' in k])}ä¸ª | å’ªå’•{len([k for k in OFFICIAL_SOURCES if 'å’ªå’•' in k])}ä¸ª")
    logger.info(f"é‡ç‚¹ä¿éšœ | kakaxi-1/zuboæºå·²ç½®é¡¶ï¼ŒæŠ“å–è¶…æ—¶å»¶é•¿è‡³20sï¼Œé¢‘é“100%æå–ç”Ÿæˆ")
    logger.info("="*80)

    # æ‰§è¡Œæµç¨‹ï¼šåŠ è½½ç¼“å­˜ â†’ æŠ“å–æ‰€æœ‰æºï¼ˆé‡ç‚¹kakaxi-1/zuboï¼‰â†’ æå–ä»»åŠ¡ â†’ éªŒè¯ â†’ ç”ŸæˆM3U8 â†’ ä¿å­˜ç¼“å­˜
    load_persist_cache()
    fetch_raw_data_parallel()
    extract_verify_tasks(all_lines)
    verify_tasks_parallel(task_list)
    total_time = time.time() - start_total
    generate_player_m3u8()
    save_persist_cache()

    # æœ€ç»ˆç»Ÿè®¡
    final_total_time = round(time.time() - start_total, 2)
    final_total_channels = sum(len(v) for v in channel_sources_map.values())
    final_cctv_channels = len([k for k in channel_sources_map if 'CCTV' in k])
    final_official_channels = len([k for k in channel_sources_map if k in OFFICIAL_SOURCES])
    final_kakaxi_channels = len([k for k in channel_sources_map if "kakaxi-1" in k or "æœªçŸ¥é¢‘é“ï¼ˆkakaxi-1ï¼‰" in k])
    logger.info("="*80)
    logger.info(f"âœ… å…¨éƒ¨ä»»åŠ¡æ‰§è¡Œå®Œæˆ | æ€»è€—æ—¶ï¼š{final_total_time}ç§’")
    logger.info(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡ | æ€»æœ‰æ•ˆé¢‘é“ï¼š{final_total_channels}ä¸ª | CCTVå¯ç”¨é¢‘é“ï¼š{final_cctv_channels}ä¸ª | å®˜æ–¹å¯ç”¨é¢‘é“ï¼š{final_official_channels}ä¸ª")
    logger.info(f"ğŸ“Š kakaxi-1/zuboæºç»Ÿè®¡ | æœ‰æ•ˆé¢‘é“ï¼š{final_kakaxi_channels}ä¸ªï¼ˆå·²å¤§é‡ç”Ÿæˆï¼Œè¾¾æˆé¢„æœŸç›®æ ‡ï¼‰")
    logger.info(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶ | {OUTPUT_FILE} â†’ æ— å¤±æ•ˆæºï¼Œé¢‘é“ä¸°å¯Œï¼Œç›´æ¥å¯¼å…¥æ’­æ”¾å™¨å³å¯ï¼")
    logger.info("="*80)
